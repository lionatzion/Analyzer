{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWsK4Pf6QXaKuCG5e0IYlr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lionatzion/Analyzer/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ-U040aXeL5"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install moviepy openai matplotlib numpy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install moviepy openai matplotlib numpy --quiet"
      ],
      "metadata": {
        "id": "3X9oPKz5cBpC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKSbbxhVcISM",
        "outputId": "bba9c6a3-bee1-4442-c71c-c8a552336a13"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” CONFIGURATION â€”â€”â€”â€”â€”\n",
        "# Use Colab's file system\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "VIDEO_PATH = os.path.join(OUTPUT_DIR, \"agentic_ai_presentation.mp4\")\n",
        "FPS = 24\n",
        "SLIDE_DURATION = 30  # seconds per slide (Adjust if needed based on TTS length)\n",
        "WIDTH, HEIGHT = 1280, 720\n",
        "BG_COLOR = (31, 41, 55)  # dark gray as RGB tuple\n",
        "ACCENT_COLOR = \"#FF6A00\"  # orange accent (Used potentially in charts)\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6KFdXI4cNm0",
        "outputId": "a992f083-9634-4965-c6f5-adcb40d76946"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output will be saved to: /content/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” SLIDE CONTENT â€”â€”â€”â€”â€”\n",
        "# (Keep your original slides list here)\n",
        "slides = [\n",
        "    {\n",
        "        \"title\": \"Welcome to Agentic AI\",\n",
        "        \"script\": (\n",
        "            \"Welcome to our exploration of Agentic AI. In the next three and a half minutes, \"\n",
        "            \"we'll dive into a transformative technology shaping the future of intelligent systems. \"\n",
        "            \"Agentic AI enables machines not only to analyze data but also to make autonomous decisions, \"\n",
        "            \"adapt to new contexts, and pursue high-level objectives with minimal human intervention. \"\n",
        "            \"We'll cover its definition, key components, benefits, challenges, real-world use cases, \"\n",
        "            \"and future outlook. Let's get started!\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"What is Agentic AI?\",\n",
        "        \"script\": (\n",
        "            \"At its essence, Agentic AI refers to AI systems endowed with agencyâ€”the capacity to act autonomously \"\n",
        "            \"to achieve goals. It goes beyond traditional AI, which typically executes predefined tasks based on \"\n",
        "            \"pattern recognition or rules. Agentic AI employs perception modules to interpret sensory data, reasoning \"\n",
        "            \"engines to plan actions, and actuation to execute decisions in the world. This triad is the backbone of autonomy.\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Core Components\",\n",
        "        \"script\": (\n",
        "            \"Agentic AIâ€™s core components are perception, reasoning, and actuation. Perception transforms raw inputs \"\n",
        "            \"into meaningful data. Reasoning plans and optimizes actionsâ€”often via reinforcement learning or planning \"\n",
        "            \"algorithms. Actuation interfaces with robots or software APIs to effect change. Together, they form a \"\n",
        "            \"closed loop enabling continuous, autonomous operation.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Perception\", 30), (\"Reasoning\", 30), (\"Actuation\", 40)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Benefits\",\n",
        "        \"script\": (\n",
        "            \"Agentic AI brings efficiency by automating decisions, scalability by adapting without reprogramming, \"\n",
        "            \"and personalization by tailoring interactions in real time. Whether in customer service, logistics, or \"\n",
        "            \"data analytics, these systems reduce costs, accelerate workflows, and unlock new innovation.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Efficiency\", 40), (\"Scalability\", 35), (\"Personalization\", 25)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Challenges\",\n",
        "        \"script\": (\n",
        "            \"Challenges include ethicsâ€”autonomous decisions need accountability and transparencyâ€”complexity, which \"\n",
        "            \"drives up development costs, and trust: ensuring safety in unpredictable environments. Regulatory \"\n",
        "            \"compliance in healthcare, finance, and beyond also demands clear governance frameworks.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Ethics\", 30), (\"Complexity\", 45), (\"Trust\", 25)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Real-World Use Cases\",\n",
        "        \"script\": (\n",
        "            \"Agentic AI powers warehouse robots that navigate dynamic spaces, trading bots making real-time market \"\n",
        "            \"decisions, and conversational agents handling complex queries. In smart cities, it optimizes traffic \"\n",
        "            \"and energy. These examples show how autonomous decision-making is already transforming industries.\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Future Outlook & Conclusion\",\n",
        "        \"script\": (\n",
        "            \"Looking ahead, hybrid architectures combining symbolic reasoning and deep learning will boost robustness. \"\n",
        "            \"Embedding explainability and fairness will build trust. As Agentic AI matures, weâ€™ll see more self-managing \"\n",
        "            \"enterprises and humanâ€“AI collaborations. Thank you for joining this journey into Agentic AIâ€”exciting times lie ahead!\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "9YHYpNoxcSE7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” HELPERS â€”â€”â€”â€”â€”\n",
        "def generate_tts(text: str, out_path: str):\n",
        "    \"\"\"\n",
        "    Uses OpenAIâ€™s TTS (Onyx voice) to synthesize a .mp3 file.\n",
        "    Requires the openai library and API key to be configured.\n",
        "    \"\"\"\n",
        "    if not openai.api_key:\n",
        "      print(\"Skipping TTS generation as OpenAI API key is not configured.\")\n",
        "      # Create a dummy empty file to avoid errors later\n",
        "      with open(out_path, \"wb\") as f:\n",
        "          pass # Write nothing, creates an empty file\n",
        "      return False # Indicate failure or skipping\n",
        "\n",
        "    try:\n",
        "        # Note: OpenAI API might return audio data directly, not response object\n",
        "        # Check documentation if API changes. Current SDK uses .audio property\n",
        "        response = openai.audio.speech.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"onyx\",\n",
        "            input=text\n",
        "        )\n",
        "        # The response object has a 'write_to_file' method or you can stream bytes\n",
        "        response.stream_to_file(out_path)\n",
        "        # Old way (might still work depending on version):\n",
        "        # with open(out_path, \"wb\") as f:\n",
        "        #     f.write(response.audio) # Access audio bytes if needed\n",
        "        return True # Indicate success\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating TTS for path {out_path}: {e}\")\n",
        "        # Create a dummy empty file to avoid errors later\n",
        "        with open(out_path, \"wb\") as f:\n",
        "            pass # Write nothing\n",
        "        return False # Indicate failure"
      ],
      "metadata": {
        "id": "bBiDqyWhcbq8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” MAIN PROCESSING â€”â€”â€”â€”â€”\n",
        "\n",
        "# 1. Generate narration audio\n",
        "print(\"--- Generating Narration Audio ---\")\n",
        "audio_files = []\n",
        "actual_audio_durations = []\n",
        "if openai.api_key: # Only proceed if key is available\n",
        "    for idx, slide in enumerate(slides):\n",
        "        audio_path = os.path.join(OUTPUT_DIR, f\"slide_{idx}.mp3\")\n",
        "        print(f\"Rendering TTS for slide {idx+1}/{len(slides)}...\")\n",
        "        success = generate_tts(slide[\"script\"], audio_path)\n",
        "        audio_files.append(audio_path)\n",
        "        if success and os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:\n",
        "             # Get actual duration for potentially adjusting slide timing later\n",
        "             try:\n",
        "                 temp_audio_clip = AudioFileClip(audio_path)\n",
        "                 actual_audio_durations.append(temp_audio_clip.duration)\n",
        "                 temp_audio_clip.close() # Close the clip to release file handle\n",
        "             except Exception as e:\n",
        "                 print(f\"Warning: Could not get duration for {audio_path}. Using default. Error: {e}\")\n",
        "                 actual_audio_durations.append(SLIDE_DURATION) # Fallback\n",
        "        else:\n",
        "             print(f\"Warning: TTS failed or produced empty file for slide {idx+1}. Using default duration.\")\n",
        "             actual_audio_durations.append(SLIDE_DURATION) # Fallback if TTS failed\n",
        "else:\n",
        "    print(\"Skipping TTS generation as API key is missing.\")\n",
        "    # Create placeholder entries if TTS is skipped\n",
        "    audio_files = [os.path.join(OUTPUT_DIR, f\"slide_{idx}.mp3\") for idx in range(len(slides))]\n",
        "    actual_audio_durations = [SLIDE_DURATION] * len(slides) # Use default duration\n",
        "    # Ensure dummy files exist if generate_tts didn't create them\n",
        "    for audio_path in audio_files:\n",
        "        if not os.path.exists(audio_path):\n",
        "            with open(audio_path, 'wb') as f: pass\n",
        "\n",
        "print(f\"Actual audio durations (seconds): {actual_audio_durations}\")\n",
        "# Optional: You could adjust SLIDE_DURATION dynamically based on these actuals\n",
        "# For simplicity, we'll stick to the fixed SLIDE_DURATION for video clips,\n",
        "# but the concatenated audio will have its real length. Moviepy handles this.\n",
        "\n",
        "# 2. Generate infographics\n",
        "print(\"\\n--- Generating Infographics ---\")\n",
        "chart_paths = {}\n",
        "for idx, slide in enumerate(slides):\n",
        "    if slide.get(\"infographic\"):\n",
        "        chart_path = os.path.join(OUTPUT_DIR, f\"chart_{idx}.png\")\n",
        "        print(f\"Generating chart for slide {idx+1}...\")\n",
        "        try:\n",
        "            labels, vals = zip(*slide[\"chart_data\"])\n",
        "            fig, ax = plt.subplots(figsize=(6, 4)) # Slightly bigger figure\n",
        "            bars = ax.bar(labels, vals, color=ACCENT_COLOR)\n",
        "            ax.set_title(slide[\"title\"], fontsize=14, color='white')\n",
        "            ax.tick_params(axis='x', colors='white', labelsize=10)\n",
        "            ax.set_yticks([]) # Hide Y axis ticks/labels\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.spines['left'].set_visible(False)\n",
        "            ax.spines['bottom'].set_color('white')\n",
        "            ax.set_facecolor(f'rgb{BG_COLOR}') # Match background\n",
        "            fig.patch.set_facecolor(f'rgb{BG_COLOR}') # Match figure background too\n",
        "\n",
        "            # Add value labels on top of bars\n",
        "            for bar in bars:\n",
        "              height = bar.get_height()\n",
        "              ax.annotate(f'{height}',\n",
        "                          xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                          xytext=(0, 3),  # 3 points vertical offset\n",
        "                          textcoords=\"offset points\",\n",
        "                          ha='center', va='bottom', color='white', fontsize=10)\n",
        "\n",
        "            plt.savefig(chart_path, bbox_inches=\"tight\", facecolor=fig.get_facecolor(), transparent=True) # Use transparent BG on save\n",
        "            plt.close(fig) # Close the figure to free memory\n",
        "            chart_paths[idx] = chart_path\n",
        "            print(f\"Chart saved to {chart_path}\")\n",
        "            # Display the chart in Colab output\n",
        "            ipd.display(ipd.Image(chart_path))\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating chart for slide {idx+1}: {e}\")\n",
        "\n",
        "print(\"\\nInfographics generation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hB8puVECciSy",
        "outputId": "e9ae42eb-5217-49ac-c5c2-8cef0d0bc709"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Narration Audio ---\n",
            "Skipping TTS generation as API key is missing.\n",
            "Actual audio durations (seconds): [30, 30, 30, 30, 30, 30, 30]\n",
            "\n",
            "--- Generating Infographics ---\n",
            "Generating chart for slide 3...\n",
            "Error generating chart for slide 3: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "Generating chart for slide 4...\n",
            "Error generating chart for slide 4: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "Generating chart for slide 5...\n",
            "Error generating chart for slide 5: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "\n",
            "Infographics generation complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAF3CAYAAACbnlMqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABjhJREFUeJzt2MFNxFAQBUGMfOBCpI7H8Q4HUsBM76oqgXkHS63vY2bmAwBY97k9AAD4JcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAEHGuXr+O1fP8g3u2FwC8DC9lAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiDi3B8AjrmN7AU+7Z3sB/DkvZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIg4twcAvJTr2F7A0+5ZO+2lDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAAR5+r1r+/V87wx3xZP8W3xoGNmZnsEAOD3NQBkiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAET8AD16ESzOT2RVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAF3CAYAAACbnlMqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABjhJREFUeJzt2MFNxFAQBUGMfOBCpI7H8Q4HUsBM76oqgXkHS63vY2bmAwBY97k9AAD4JcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAEHFuD4BHXMf2Ap52z/YC+HNeygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQca5ev47V8/yDe7YXALwML2UAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiDi3BwC8lOvYXsDT7lk77aUMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAAR5+r1r+/V87wx3xZP8W3xoGNmZnsEAOD3NQBkiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAET8AN7iESzy4iBPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Build video clips\n",
        "print(\"\\n--- Building Video Clips ---\")\n",
        "clips = []\n",
        "# Use actual audio durations if available, otherwise default SLIDE_DURATION\n",
        "# slide_durations_to_use = [max(a, 5) for a in actual_audio_durations] # Ensure min 5s duration? Or just use fixed?\n",
        "# Let's stick to fixed duration for video simplicity, audio will dictate final length anyway\n",
        "slide_durations_to_use = [SLIDE_DURATION] * len(slides)\n",
        "\n",
        "for idx, slide in enumerate(slides):\n",
        "    print(f\"Creating video clip for slide {idx+1}/{len(slides)}...\")\n",
        "    duration = slide_durations_to_use[idx]\n",
        "\n",
        "    # background\n",
        "    bg_array = np.full((HEIGHT, WIDTH, 3), BG_COLOR, dtype=np.uint8)\n",
        "    bg = ImageClip(bg_array).set_duration(duration)\n",
        "\n",
        "    # title text\n",
        "    txt_clip = TextClip(\n",
        "        slide[\"title\"],\n",
        "        fontsize=70, # Slightly larger font\n",
        "        font=\"DejaVu-Sans-Bold\", # A common font available in Colab/Linux environments\n",
        "        color=\"white\",\n",
        "        size=(WIDTH*0.8, None), # Limit width\n",
        "        method='caption' # Allow wrapping\n",
        "    ).set_position((\"center\", 0.1), relative=True).set_duration(duration) # Position 10% from top\n",
        "\n",
        "    layers = [bg, txt_clip]\n",
        "\n",
        "    # infographic overlay\n",
        "    if slide.get(\"infographic\") and idx in chart_paths:\n",
        "        try:\n",
        "            chart_clip = (\n",
        "                ImageClip(chart_paths[idx], transparent=True) # Load with transparency\n",
        "                .resize(height=HEIGHT * 0.5) # Relative sizing\n",
        "                .set_position((\"center\", \"center\")) # Center the chart\n",
        "                .set_duration(duration)\n",
        "                # Optional fade in/out effect for chart\n",
        "                # .crossfadein(1.0).crossfadeout(1.0)\n",
        "            )\n",
        "            layers.append(chart_clip)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load or add chart for slide {idx+1}. Error: {e}\")\n",
        "\n",
        "\n",
        "    final_clip = CompositeVideoClip(layers, size=(WIDTH, HEIGHT))\n",
        "    clips.append(final_clip)\n",
        "\n",
        "print(\"Video clip creation complete.\")\n",
        "\n",
        "# 4. Concatenate video + audio\n",
        "print(\"\\n--- Concatenating Video and Audio ---\")\n",
        "try:\n",
        "    video = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "    # Load valid audio clips\n",
        "    valid_audios = []\n",
        "    for idx, p in enumerate(audio_files):\n",
        "        if os.path.exists(p) and os.path.getsize(p) > 0:\n",
        "             try:\n",
        "                audio_clip = AudioFileClip(p)\n",
        "                # Optional: Add padding if audio is shorter than SLIDE_DURATION?\n",
        "                # Or just let the final video length be dictated by audio.\n",
        "                valid_audios.append(audio_clip)\n",
        "             except Exception as e:\n",
        "                 print(f\"Warning: Could not load audio file {p}. Skipping. Error: {e}\")\n",
        "        else:\n",
        "             print(f\"Warning: Audio file {p} is missing or empty. Skipping.\")\n",
        "\n",
        "    if valid_audios:\n",
        "        full_audio = concatenate_audioclips(valid_audios)\n",
        "        # Trim or pad video to match total audio duration\n",
        "        print(f\"Total audio duration: {full_audio.duration:.2f}s\")\n",
        "        print(f\"Total video duration before audio sync: {video.duration:.2f}s\")\n",
        "        video = video.set_duration(full_audio.duration)\n",
        "        video = video.set_audio(full_audio)\n",
        "        print(f\"Video duration set to match audio: {video.duration:.2f}s\")\n",
        "    else:\n",
        "        print(\"No valid audio found. Video will be silent.\")\n",
        "        # If no audio, set video duration based on SLIDE_DURATION sum\n",
        "        video = video.set_duration(sum(slide_durations_to_use))\n",
        "\n",
        "\n",
        "    # 5. Export\n",
        "    print(f\"\\n--- Exporting Video ---\")\n",
        "    print(f\"Writing video to: {VIDEO_PATH}\")\n",
        "    video.write_videofile(\n",
        "        VIDEO_PATH,\n",
        "        fps=FPS,\n",
        "        codec=\"libx264\",\n",
        "        audio_codec=\"aac\",\n",
        "        temp_audiofile=os.path.join(OUTPUT_DIR, \"temp-audio.m4a\"), # Ensure temp file is in output dir\n",
        "        remove_temp=True,\n",
        "        preset='medium', # encoding preset\n",
        "        logger='bar' # Show progress bar\n",
        "    )\n",
        "\n",
        "    print(f\"\\nâœ… Presentation done: {VIDEO_PATH}\")\n",
        "\n",
        "    # Clean up intermediate files (optional)\n",
        "    # print(\"\\nCleaning up intermediate files...\")\n",
        "    # for idx in range(len(slides)):\n",
        "    #     audio_path = os.path.join(OUTPUT_DIR, f\"slide_{idx}.mp3\")\n",
        "    #     chart_path = os.path.join(OUTPUT_DIR, f\"chart_{idx}.png\")\n",
        "    #     if os.path.exists(audio_path): os.remove(audio_path)\n",
        "    #     if os.path.exists(chart_path): os.remove(chart_path)\n",
        "    # print(\"Cleanup complete.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ An error occurred during video processing or export: {e}\")\n",
        "\n",
        "finally:\n",
        "    # Ensure all moviepy clips are closed to release resources\n",
        "    for clip in clips:\n",
        "        clip.close()\n",
        "    if 'full_audio' in locals() and full_audio:\n",
        "        full_audio.close()\n",
        "    for audio_clip in valid_audios:\n",
        "         audio_clip.close()\n",
        "    if 'video' in locals() and video:\n",
        "        video.close()\n",
        "    print(\"Resources closed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "RNp4K5CecmpJ",
        "outputId": "02fe00b2-8cc4-4365-b44b-5c5669e9663c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building Video Clips ---\n",
            "Creating video clip for slide 1/7...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "MoviePy Error: creation of None failed because of the following error:\n\n[Errno 2] No such file or directory: 'unset'.\n\n.This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, txt, filename, size, color, bg_color, fontsize, font, stroke_color, stroke_width, method, kerning, align, interline, tempfilename, temptxt, transparent, remove_temp, print_cmd)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m             \u001b[0msubprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/moviepy/tools.py\u001b[0m in \u001b[0;36msubprocess_call\u001b[0;34m(cmd, logger, errorprint)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpopen_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1954\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merr_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'unset'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-95f7e078348b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# title text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     txt_clip = TextClip(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mslide\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Slightly larger font\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, txt, filename, size, color, bg_color, fontsize, font, stroke_color, stroke_width, method, kerning, align, interline, tempfilename, temptxt, transparent, remove_temp, print_cmd)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                         \u001b[0;34m\"ImageMagick binary in file conf.py, or that the path \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                         \"you specified is incorrect\"))\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mImageClip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: MoviePy Error: creation of None failed because of the following error:\n\n[Errno 2] No such file or directory: 'unset'.\n\n.This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary Python libraries\n",
        "!pip install moviepy openai matplotlib numpy --quiet\n",
        "print(\"Python libraries installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQjhsqxNdUY8",
        "outputId": "ad4419be-ea4b-4aa6-be2d-24c419309082"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python libraries installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ImageMagick for MoviePy TextClip\n",
        "!apt-get update -qq && apt-get install -qq -y imagemagick\n",
        "print(\"ImageMagick installation attempted.\")\n",
        "print(\"âœ… ====> IMPORTANT: Please RESTART the Runtime now! <==== âœ…\")\n",
        "print(\"Go to 'Runtime' -> 'Restart runtime' before running the next cells.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYQqne3mdczP",
        "outputId": "7d3435c2-549a-443b-cfc7-2416f419af04"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 126333 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../01-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../02-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../03-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../04-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickwand-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.11_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.11_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.11_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../16-imagemagick-6.q16_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../17-imagemagick_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../18-libdjvulibre-text_3.5.28-2build2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../19-libdjvulibre21_3.5.28-2build2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libjxr0:amd64.\n",
            "Preparing to unpack .../20-libjxr0_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libjxr-tools.\n",
            "Preparing to unpack .../21-libjxr-tools_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libwmflite-0.2-7:amd64.\n",
            "Preparing to unpack .../22-libwmflite-0.2-7_0.2.12-5ubuntu1_amd64.deb ...\n",
            "Unpacking libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6-extra:amd64.\n",
            "Preparing to unpack .../23-libmagickcore-6.q16-6-extra_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../24-libnetpbm10_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.4) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../25-netpbm_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.4) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.4) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up netpbm (2:10.0-15.4) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libdjvulibre-text (3.5.28-2build2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Setting up libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.11) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "ImageMagick installation attempted.\n",
            "âœ… ====> IMPORTANT: Please RESTART the Runtime now! <==== âœ…\n",
            "Go to 'Runtime' -> 'Restart runtime' before running the next cells.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Check if runtime was restarted - suppress warnings if ImageMagick is found now\n",
        "try:\n",
        "    import moviepy.config as mpy_config\n",
        "    if mpy_config.get_setting(\"IMAGEMAGICK_BINARY\") == 'auto-detect':\n",
        "         print(\"ImageMagick likely found by MoviePy.\")\n",
        "except Exception:\n",
        "    pass # Ignore if moviepy config check fails\n",
        "\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "import shutil # For checking if ImageMagick is available\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "openai_key_loaded = False\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        print(\"âš ï¸ OpenAI API key not found or empty in Colab secrets.\")\n",
        "        print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "    else:\n",
        "        print(\"âœ… OpenAI API key loaded successfully.\")\n",
        "        openai_key_loaded = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error loading OpenAI API key: {e}\")\n",
        "    print(\"   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\")\n",
        "    print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "\n",
        "# Verify ImageMagick installation (optional but good check)\n",
        "if shutil.which(\"convert\"):\n",
        "    print(\"âœ… ImageMagick 'convert' command found in PATH.\")\n",
        "else:\n",
        "    print(\"âš ï¸ ImageMagick 'convert' command NOT found. TextClip might still fail.\")\n",
        "    print(\"   Ensure you restarted the runtime after running Cell 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znvhCCBYeUp0",
        "outputId": "5f794512-7a12-4325-91d4-4b61df89f30e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\n",
            "   TTS generation will be skipped. Video will have no audio.\n",
            "âœ… ImageMagick 'convert' command found in PATH.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsNq9RzTekWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secretName')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "z8c-QdeVeoFL",
        "outputId": "ba1f0ffb-bc24-4490-b34b-27ddd61dd38b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret secretName does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-245876ae012f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'secretName'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret secretName does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Check if runtime was restarted - suppress warnings if ImageMagick is found now\n",
        "try:\n",
        "    import moviepy.config as mpy_config\n",
        "    if mpy_config.get_setting(\"IMAGEMAGICK_BINARY\") == 'auto-detect':\n",
        "         print(\"ImageMagick likely found by MoviePy.\")\n",
        "except Exception:\n",
        "    pass # Ignore if moviepy config check fails\n",
        "\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "import shutil # For checking if ImageMagick is available\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "openai_key_loaded = False\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        print(\"âš ï¸ OpenAI API key not found or empty in Colab secrets.\")\n",
        "        print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "    else:\n",
        "        print(\"âœ… OpenAI API key loaded successfully.\")\n",
        "        openai_key_loaded = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error loading OpenAI API key: {e}\")\n",
        "    print(\"   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\")\n",
        "    print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "\n",
        "# Verify ImageMagick installation (optional but good check)\n",
        "if shutil.which(\"convert\"):\n",
        "    print(\"âœ… ImageMagick 'convert' command found in PATH.\")\n",
        "else:\n",
        "    print(\"âš ï¸ ImageMagick 'convert' command NOT found. TextClip might still fail.\")\n",
        "    print(\"   Ensure you restarted the runtime after running Cell 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pudtTUWketVW",
        "outputId": "49bb176f-41c1-48cc-8b52-34f780a105fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\n",
            "   TTS generation will be skipped. Video will have no audio.\n",
            "âœ… ImageMagick 'convert' command found in PATH.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Check if runtime was restarted - suppress warnings if ImageMagick is found now\n",
        "try:\n",
        "    import moviepy.config as mpy_config\n",
        "    if mpy_config.get_setting(\"IMAGEMAGICK_BINARY\") == 'auto-detect':\n",
        "         print(\"ImageMagick likely found by MoviePy.\")\n",
        "except Exception:\n",
        "    pass # Ignore if moviepy config check fails\n",
        "\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "import shutil # For checking if ImageMagick is available\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "openai_key_loaded = False\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        print(\"âš ï¸ OpenAI API key not found or empty in Colab secrets.\")\n",
        "        print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "    else:\n",
        "        print(\"âœ… OpenAI API key loaded successfully.\")\n",
        "        openai_key_loaded = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error loading OpenAI API key: {e}\")\n",
        "    print(\"   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\")\n",
        "    print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "\n",
        "# Verify ImageMagick installation (optional but good check)\n",
        "if shutil.which(\"convert\"):\n",
        "    print(\"âœ… ImageMagick 'convert' command found in PATH.\")\n",
        "else:\n",
        "    print(\"âš ï¸ ImageMagick 'convert' command NOT found. TextClip might still fail.\")\n",
        "    print(\"   Ensure you restarted the runtime after running Cell 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjzBi0VtexPi",
        "outputId": "f6490874-41a5-4c65-e284-7d6c64fe5bbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\n",
            "   TTS generation will be skipped. Video will have no audio.\n",
            "âœ… ImageMagick 'convert' command found in PATH.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Check if runtime was restarted - suppress warnings if ImageMagick is found now\n",
        "try:\n",
        "    import moviepy.config as mpy_config\n",
        "    if mpy_config.get_setting(\"IMAGEMAGICK_BINARY\") == 'auto-detect':\n",
        "         print(\"ImageMagick likely found by MoviePy.\")\n",
        "except Exception:\n",
        "    pass # Ignore if moviepy config check fails\n",
        "\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "import shutil # For checking if ImageMagick is available"
      ],
      "metadata": {
        "id": "yAdRIIuPe-EB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API key from Colab secrets\n",
        "openai_key_loaded = False\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        print(\"âš ï¸ OpenAI API key not found or empty in Colab secrets.\")\n",
        "        print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "    else:\n",
        "        print(\"âœ… OpenAI API key loaded successfully.\")\n",
        "        openai_key_loaded = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error loading OpenAI API key: {e}\")\n",
        "    print(\"   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\")\n",
        "    print(\"   TTS generation will be skipped. Video will have no audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "53x2XW3JfBLt",
        "outputId": "75257154-f8b0-4382-e661-8ddf54b62cd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 14) (<ipython-input-6-e7c19f664730>, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-e7c19f664730>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    print(\"   TTS generation will be skipped. Video will have no audio\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_key_loaded = False\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        print(\"âš ï¸ OpenAI API key not found or empty in Colab secrets.\")\n",
        "        print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "    else:\n",
        "        print(\"âœ… OpenAI API key loaded successfully.\")\n",
        "        openai_key_loaded = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error loading OpenAI API key: {e}\")\n",
        "    print(\"   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\")\n",
        "    print(\"   TTS generation will be skipped. Video will have no audio.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eWHILzkfMn9",
        "outputId": "d803991b-60b5-4352-bc51-ff732d7ab49d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\n",
            "   TTS generation will be skipped. Video will have no audio.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API key from Colab secrets\n",
        "openai_key_loaded = False\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        print(\"âš ï¸ OpenAI API key not found or empty in Colab secrets.\")\n",
        "        print(\"   TTS generation will be skipped. Video will have no audio.\")\n",
        "    else:\n",
        "        print(\"âœ… OpenAI API key loaded successfully.\")\n",
        "        openai_key_loaded = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error loading OpenAI API key: {e}\")\n",
        "    print(\"   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\")\n",
        "    print(\"   TTS generation will be skipped. Video will have no audio.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP2eJduNfPv7",
        "outputId": "df61ab7f-4ebe-4760-fcfb-0c3e95ed3ba6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "   Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets.\n",
            "   TTS generation will be skipped. Video will have no audio.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if shutil.which(\"convert\"):\n",
        "    print(\"âœ… ImageMagick 'convert' command found in PATH.\")\n",
        "else:\n",
        "    print(\"âš ï¸ ImageMagick 'convert' command NOT found. TextClip might still fail.\")\n",
        "    print(\"   Ensure you restarted the runtime after running Cell 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyDz5dSDfTYZ",
        "outputId": "7b630426-1534-45e2-d7f8-e51f4367d5b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ImageMagick 'convert' command found in PATH.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” CONFIGURATION â€”â€”â€”â€”â€”\n",
        "# Use Colab's file system\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "VIDEO_PATH = os.path.join(OUTPUT_DIR, \"agentic_ai_presentation.mp4\")\n",
        "FPS = 24\n",
        "SLIDE_DURATION = 30  # Default seconds per slide (Audio may override final duration)\n",
        "WIDTH, HEIGHT = 1280, 720\n",
        "BG_COLOR = (31, 41, 55)  # dark gray as RGB tuple\n",
        "ACCENT_COLOR = \"#FF6A00\"  # orange accent (Used potentially in charts)\n",
        "AVAILABLE_FONT = \"DejaVu-Sans-Bold\" # A font usually available in Colab\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output directory set to: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1JcHCT0fVXl",
        "outputId": "93634ab1-499c-42e1-a3a9-dfd47bcb94ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory set to: /content/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” SLIDE CONTENT â€”â€”â€”â€”â€”\n",
        "# (Keep your original slides list here)\n",
        "slides = [\n",
        "    {\n",
        "        \"title\": \"Welcome to Agentic AI\",\n",
        "        \"script\": (\n",
        "            \"Welcome to our exploration of Agentic AI. In the next three and a half minutes, \"\n",
        "            \"we'll dive into a transformative technology shaping the future of intelligent systems. \"\n",
        "            \"Agentic AI enables machines not only to analyze data but also to make autonomous decisions, \"\n",
        "            \"adapt to new contexts, and pursue high-level objectives with minimal human intervention. \"\n",
        "            \"We'll cover its definition, key components, benefits, challenges, real-world use cases, \"\n",
        "            \"and future outlook. Let's get started!\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"What is Agentic AI?\",\n",
        "        \"script\": (\n",
        "            \"At its essence, Agentic AI refers to AI systems endowed with agencyâ€”the capacity to act autonomously \"\n",
        "            \"to achieve goals. It goes beyond traditional AI, which typically executes predefined tasks based on \"\n",
        "            \"pattern recognition or rules. Agentic AI employs perception modules to interpret sensory data, reasoning \"\n",
        "            \"engines to plan actions, and actuation to execute decisions in the world. This triad is the backbone of autonomy.\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Core Components\",\n",
        "        \"script\": (\n",
        "            \"Agentic AIâ€™s core components are perception, reasoning, and actuation. Perception transforms raw inputs \"\n",
        "            \"into meaningful data. Reasoning plans and optimizes actionsâ€”often via reinforcement learning or planning \"\n",
        "            \"algorithms. Actuation interfaces with robots or software APIs to effect change. Together, they form a \"\n",
        "            \"closed loop enabling continuous, autonomous operation.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Perception\", 30), (\"Reasoning\", 30), (\"Actuation\", 40)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Benefits\",\n",
        "        \"script\": (\n",
        "            \"Agentic AI brings efficiency by automating decisions, scalability by adapting without reprogramming, \"\n",
        "            \"and personalization by tailoring interactions in real time. Whether in customer service, logistics, or \"\n",
        "            \"data analytics, these systems reduce costs, accelerate workflows, and unlock new innovation.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Efficiency\", 40), (\"Scalability\", 35), (\"Personalization\", 25)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Challenges\",\n",
        "        \"script\": (\n",
        "            \"Challenges include ethicsâ€”autonomous decisions need accountability and transparencyâ€”complexity, which \"\n",
        "            \"drives up development costs, and trust: ensuring safety in unpredictable environments. Regulatory \"\n",
        "            \"compliance in healthcare, finance, and beyond also demands clear governance frameworks.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Ethics\", 30), (\"Complexity\", 45), (\"Trust\", 25)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Real-World Use Cases\",\n",
        "        \"script\": (\n",
        "            \"Agentic AI powers warehouse robots that navigate dynamic spaces, trading bots making real-time market \"\n",
        "            \"decisions, and conversational agents handling complex queries. In smart cities, it optimizes traffic \"\n",
        "            \"and energy. These examples show how autonomous decision-making is already transforming industries.\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Future Outlook & Conclusion\",\n",
        "        \"script\": (\n",
        "            \"Looking ahead, hybrid architectures combining symbolic reasoning and deep learning will boost robustness. \"\n",
        "            \"Embedding explainability and fairness will build trust. As Agentic AI matures, weâ€™ll see more self-managing \"\n",
        "            \"enterprises and humanâ€“AI collaborations. Thank you for joining this journey into Agentic AIâ€”exciting times lie ahead!\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    }\n",
        "]\n",
        "print(f\"{len(slides)} slides defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMeACChSfW-6",
        "outputId": "3a7ca697-9788-4462-d0c7-ac605871c0f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 slides defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” HELPERS â€”â€”â€”â€”â€”\n",
        "def generate_tts(text: str, out_path: str):\n",
        "    \"\"\"\n",
        "    Uses OpenAIâ€™s TTS (Onyx voice) to synthesize a .mp3 file.\n",
        "    Requires the openai library and API key to be configured.\n",
        "    Returns True on success, False otherwise.\n",
        "    \"\"\"\n",
        "    global openai_key_loaded # Use the global flag\n",
        "    if not openai_key_loaded:\n",
        "      # print(\"Skipping TTS generation as OpenAI API key is not configured.\")\n",
        "      # Create a dummy empty file to avoid errors later if needed\n",
        "      # with open(out_path, \"wb\") as f: pass\n",
        "      return False # Indicate skipping\n",
        "\n",
        "    try:\n",
        "        # Use the stream_to_file method for efficient writing\n",
        "        response = openai.audio.speech.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"onyx\",\n",
        "            input=text\n",
        "        )\n",
        "        response.stream_to_file(out_path)\n",
        "        # Check if file was actually created and has size\n",
        "        if os.path.exists(out_path) and os.path.getsize(out_path) > 0:\n",
        "            return True # Indicate success\n",
        "        else:\n",
        "            print(f\"Warning: TTS generation seemed to succeed but {out_path} is missing or empty.\")\n",
        "            return False # Indicate failure\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating TTS for path {out_path}: {e}\")\n",
        "        # Attempt to create an empty file to prevent downstream errors if file is expected\n",
        "        try:\n",
        "            with open(out_path, \"wb\") as f: pass\n",
        "        except Exception:\n",
        "            pass # Ignore if even dummy file creation fails\n",
        "        return False # Indicate failure\n",
        "\n",
        "print(\"TTS Helper function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW3Ka3cZfcMC",
        "outputId": "06b50299-20e2-4485-8b1c-30db2fe9f654"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TTS Helper function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” MAIN PROCESSING (Part 1) â€”â€”â€”â€”â€”\n",
        "\n",
        "# 1. Generate narration audio\n",
        "print(\"--- Generating Narration Audio ---\")\n",
        "audio_files = []\n",
        "actual_audio_durations = []\n",
        "\n",
        "if openai_key_loaded:\n",
        "    for idx, slide in enumerate(slides):\n",
        "        audio_path = os.path.join(OUTPUT_DIR, f\"slide_{idx}.mp3\")\n",
        "        print(f\"Rendering TTS for slide {idx+1}/{len(slides)}...\")\n",
        "        success = generate_tts(slide[\"script\"], audio_path)\n",
        "        audio_files.append(audio_path)\n",
        "        if success:\n",
        "             # Get actual duration\n",
        "             try:\n",
        "                 with AudioFileClip(audio_path) as temp_audio_clip: # Use with statement\n",
        "                     duration = temp_audio_clip.duration\n",
        "                 if duration is None or duration <= 0:\n",
        "                     print(f\"Warning: Could not get valid duration for {audio_path}. Using default.\")\n",
        "                     actual_audio_durations.append(SLIDE_DURATION)\n",
        "                 else:\n",
        "                     actual_audio_durations.append(duration)\n",
        "             except Exception as e:\n",
        "                 print(f\"Warning: Could not get duration for {audio_path}. Using default. Error: {e}\")\n",
        "                 actual_audio_durations.append(SLIDE_DURATION) # Fallback\n",
        "        else:\n",
        "             print(f\"TTS failed for slide {idx+1}. Using default duration.\")\n",
        "             actual_audio_durations.append(SLIDE_DURATION) # Fallback if TTS failed\n",
        "    print(f\"Actual audio durations (seconds): {[round(d, 2) for d in actual_audio_durations]}\")\n",
        "else:\n",
        "    print(\"Skipping TTS generation as API key is missing or failed to load.\")\n",
        "    audio_files = [os.path.join(OUTPUT_DIR, f\"slide_{idx}_dummy.mp3\") for idx in range(len(slides))]\n",
        "    actual_audio_durations = [SLIDE_DURATION] * len(slides) # Use default duration\n",
        "\n",
        "\n",
        "# 2. Generate infographics\n",
        "print(\"\\n--- Generating Infographics ---\")\n",
        "chart_paths = {}\n",
        "for idx, slide in enumerate(slides):\n",
        "    if slide.get(\"infographic\"):\n",
        "        chart_path = os.path.join(OUTPUT_DIR, f\"chart_{idx}.png\")\n",
        "        print(f\"Generating chart for slide {idx+1}...\")\n",
        "        try:\n",
        "            labels, vals = zip(*slide[\"chart_data\"])\n",
        "            fig, ax = plt.subplots(figsize=(6, 4)) # Define figure and axes\n",
        "            bars = ax.bar(labels, vals, color=ACCENT_COLOR)\n",
        "            ax.set_title(slide[\"title\"], fontsize=14, color='white', pad=20) # Add padding\n",
        "            ax.tick_params(axis='x', colors='white', labelsize=10)\n",
        "            ax.set_yticks([]) # Hide Y axis ticks/labels\n",
        "            # Make spines invisible or color them\n",
        "            for spine in ['top', 'right', 'left']:\n",
        "                ax.spines[spine].set_visible(False)\n",
        "            ax.spines['bottom'].set_color('grey') # Subtle bottom spine\n",
        "            ax.set_facecolor(f'rgb{BG_COLOR}') # Match background\n",
        "            fig.patch.set_facecolor(f'rgb{BG_COLOR}') # Match figure background too\n",
        "\n",
        "            # Add value labels on top of bars\n",
        "            for bar in bars:\n",
        "              height = bar.get_height()\n",
        "              ax.annotate(f'{height}',\n",
        "                          xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                          xytext=(0, 3), textcoords=\"offset points\", # Offset text slightly\n",
        "                          ha='center', va='bottom', color='white', fontsize=10)\n",
        "\n",
        "            plt.savefig(chart_path, bbox_inches=\"tight\", facecolor=fig.get_facecolor(), transparent=True)\n",
        "            plt.close(fig) # Close the figure to free memory\n",
        "            chart_paths[idx] = chart_path\n",
        "            print(f\"Chart saved to {chart_path}\")\n",
        "            # Display the chart in Colab output\n",
        "            ipd.display(ipd.Image(chart_path))\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating chart for slide {idx+1}: {e}\")\n",
        "\n",
        "print(\"\\nInfographics generation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t_dHEF_AfeIa",
        "outputId": "119c5b3d-4bff-4662-f6ff-1a6d8fbcf2e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Narration Audio ---\n",
            "Skipping TTS generation as API key is missing or failed to load.\n",
            "\n",
            "--- Generating Infographics ---\n",
            "Generating chart for slide 3...\n",
            "Error generating chart for slide 3: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "Generating chart for slide 4...\n",
            "Error generating chart for slide 4: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "Generating chart for slide 5...\n",
            "Error generating chart for slide 5: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "\n",
            "Infographics generation complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” MAIN PROCESSING (Part 2) â€”â€”â€”â€”â€”\n",
        "\n",
        "# 3. Build video clips\n",
        "print(\"\\n--- Building Video Clips ---\")\n",
        "clips = []\n",
        "# Use actual audio durations if available and TTS was successful, otherwise default SLIDE_DURATION\n",
        "# Ensure a minimum duration for visual slides, e.g., 3 seconds.\n",
        "slide_durations_to_use = [max(3, d if openai_key_loaded else SLIDE_DURATION) for d in actual_audio_durations]\n",
        "print(f\"Video clip durations (seconds): {[round(d, 2) for d in slide_durations_to_use]}\")\n",
        "\n",
        "\n",
        "video_creation_successful = True\n",
        "try:\n",
        "    for idx, slide in enumerate(slides):\n",
        "        print(f\"Creating video clip for slide {idx+1}/{len(slides)}...\")\n",
        "        duration = slide_durations_to_use[idx]\n",
        "\n",
        "        # background\n",
        "        bg_array = np.full((HEIGHT, WIDTH, 3), BG_COLOR, dtype=np.uint8)\n",
        "        bg = ImageClip(bg_array).set_duration(duration)\n",
        "\n",
        "        # title text - Wrap in try-except block for safety\n",
        "        try:\n",
        "            txt_clip = TextClip(\n",
        "                slide[\"title\"],\n",
        "                fontsize=70,\n",
        "                font=AVAILABLE_FONT, # Use pre-defined font\n",
        "                color=\"white\",\n",
        "                size=(WIDTH*0.85, None), # Limit width slightly more\n",
        "                method='caption', # Allow wrapping\n",
        "                align='center'\n",
        "            ).set_position((\"center\", 0.1), relative=True).set_duration(duration)\n",
        "            layers = [bg, txt_clip]\n",
        "        except Exception as e:\n",
        "             print(f\"ERROR creating TextClip for slide {idx+1}: {e}\")\n",
        "             print(\"This might happen if ImageMagick is still not configured correctly.\")\n",
        "             print(\"Using background only for this slide.\")\n",
        "             layers = [bg] # Fallback to background only\n",
        "\n",
        "\n",
        "        # infographic overlay\n",
        "        if slide.get(\"infographic\") and idx in chart_paths:\n",
        "            try:\n",
        "                chart_clip = (\n",
        "                    ImageClip(chart_paths[idx], transparent=True)\n",
        "                    .resize(height=HEIGHT * 0.5) # Relative sizing\n",
        "                    .set_position((\"center\", \"center\"))\n",
        "                    .set_duration(duration)\n",
        "                    # Optional fade in/out for chart (adds render time)\n",
        "                    # .crossfadein(0.5).set_start(0.5).crossfadeout(0.5)\n",
        "                )\n",
        "                layers.append(chart_clip)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not load or add chart for slide {idx+1}. Error: {e}\")\n",
        "\n",
        "        final_clip = CompositeVideoClip(layers, size=(WIDTH, HEIGHT))\n",
        "        clips.append(final_clip)\n",
        "\n",
        "    print(\"Video clip creation complete.\")\n",
        "\n",
        "    # 4. Concatenate video + audio\n",
        "    print(\"\\n--- Concatenating Video and Audio ---\")\n",
        "\n",
        "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "    # Load valid audio clips only if TTS was attempted\n",
        "    valid_audios = []\n",
        "    total_audio_duration = 0\n",
        "    if openai_key_loaded:\n",
        "        print(\"Loading generated audio files...\")\n",
        "        for idx, p in enumerate(audio_files):\n",
        "            if os.path.exists(p) and os.path.getsize(p) > 0:\n",
        "                 try:\n",
        "                    audio_clip = AudioFileClip(p)\n",
        "                    valid_audios.append(audio_clip)\n",
        "                    total_audio_duration += audio_clip.duration\n",
        "                 except Exception as e:\n",
        "                     print(f\"Warning: Could not load audio file {p}. Skipping. Error: {e}\")\n",
        "            else:\n",
        "                 print(f\"Warning: Audio file {p} is missing or empty. Skipping.\")\n",
        "\n",
        "    if valid_audios:\n",
        "        print(f\"Concatenating {len(valid_audios)} audio clips...\")\n",
        "        full_audio = concatenate_audioclips(valid_audios)\n",
        "        # Trim or pad video to match total audio duration\n",
        "        print(f\"Total audio duration: {full_audio.duration:.2f}s\")\n",
        "        print(f\"Total video duration before audio sync: {final_video.duration:.2f}s\")\n",
        "        # Set final video duration to match concatenated audio\n",
        "        final_video = final_video.set_duration(full_audio.duration)\n",
        "        final_video = final_video.set_audio(full_audio)\n",
        "        print(f\"Video duration set to match audio: {final_video.duration:.2f}s\")\n",
        "    else:\n",
        "        print(\"No valid audio found or TTS was skipped. Video will be silent.\")\n",
        "        # Set video duration based on planned slide durations\n",
        "        final_video_duration = sum(slide_durations_to_use)\n",
        "        final_video = final_video.set_duration(final_video_duration)\n",
        "        print(f\"Video duration set to sum of slide durations: {final_video.duration:.2f}s\")\n",
        "\n",
        "\n",
        "    # 5. Export\n",
        "    print(f\"\\n--- Exporting Video ---\")\n",
        "    print(f\"Writing video to: {VIDEO_PATH}\")\n",
        "    final_video.write_videofile(\n",
        "        VIDEO_PATH,\n",
        "        fps=FPS,\n",
        "        codec=\"libx264\", # Good default codec\n",
        "        audio_codec=\"aac\", # Good default audio codec\n",
        "        temp_audiofile=os.path.join(OUTPUT_DIR, \"temp-audio.m4a\"),\n",
        "        remove_temp=True,\n",
        "        preset='medium', # 'medium' is a balance of speed and quality\n",
        "        logger='bar' # Show progress bar\n",
        "    )\n",
        "\n",
        "    print(f\"\\nâœ… Presentation generated: {VIDEO_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ An error occurred during video processing or export: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc() # Print detailed traceback\n",
        "    video_creation_successful = False\n",
        "\n",
        "finally:\n",
        "    # Ensure all moviepy clips are closed to release resources\n",
        "    print(\"\\nClosing resources...\")\n",
        "    for clip in clips:\n",
        "        if isinstance(clip, (CompositeVideoClip, ImageClip, TextClip)):\n",
        "            try: clip.close()\n",
        "            except Exception: pass\n",
        "    if 'valid_audios' in locals():\n",
        "        for audio_clip in valid_audios:\n",
        "            try: audio_clip.close()\n",
        "            except Exception: pass\n",
        "    if 'full_audio' in locals() and full_audio:\n",
        "         try: full_audio.close()\n",
        "         except Exception: pass\n",
        "    if 'final_video' in locals() and final_video:\n",
        "         try: final_video.close()\n",
        "         except Exception: pass\n",
        "    print(\"Resources closed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbKybPRWfgGC",
        "outputId": "a35cc779-fed6-4a0f-a33e-e97515a76621"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building Video Clips ---\n",
            "Video clip durations (seconds): [30, 30, 30, 30, 30, 30, 30]\n",
            "Creating video clip for slide 1/7...\n",
            "ERROR creating TextClip for slide 1: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpl3ap8obt.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpqhzx3tnb.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 2/7...\n",
            "ERROR creating TextClip for slide 2: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmphdtfet5i.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpyfl8hsw2.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 3/7...\n",
            "ERROR creating TextClip for slide 3: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmp1srzwon3.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpo3_2suet.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 4/7...\n",
            "ERROR creating TextClip for slide 4: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmp8gse2n7l.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpzz_imp19.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 5/7...\n",
            "ERROR creating TextClip for slide 5: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpxb9eg_kp.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmprvotkrd5.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 6/7...\n",
            "ERROR creating TextClip for slide 6: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpdg65t2qw.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmp8w0klxu0.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 7/7...\n",
            "ERROR creating TextClip for slide 7: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpuc8ij3ju.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmp9nosr_ug.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Video clip creation complete.\n",
            "\n",
            "--- Concatenating Video and Audio ---\n",
            "No valid audio found or TTS was skipped. Video will be silent.\n",
            "Video duration set to sum of slide durations: 210.00s\n",
            "\n",
            "--- Exporting Video ---\n",
            "Writing video to: /content/output/agentic_ai_presentation.mp4\n",
            "Moviepy - Building video /content/output/agentic_ai_presentation.mp4.\n",
            "Moviepy - Writing video /content/output/agentic_ai_presentation.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/output/agentic_ai_presentation.mp4\n",
            "\n",
            "âœ… Presentation generated: /content/output/agentic_ai_presentation.mp4\n",
            "\n",
            "Closing resources...\n",
            "Resources closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” MAIN PROCESSING (Part 2) â€”â€”â€”â€”â€”\n",
        "\n",
        "# 3. Build video clips\n",
        "print(\"\\n--- Building Video Clips ---\")\n",
        "clips = []\n",
        "# Use actual audio durations if available and TTS was successful, otherwise default SLIDE_DURATION\n",
        "# Ensure a minimum duration for visual slides, e.g., 3 seconds.\n",
        "slide_durations_to_use = [max(3, d if openai_key_loaded else SLIDE_DURATION) for d in actual_audio_durations]\n",
        "print(f\"Video clip durations (seconds): {[round(d, 2) for d in slide_durations_to_use]}\")\n",
        "\n",
        "\n",
        "video_creation_successful = True\n",
        "try:\n",
        "    for idx, slide in enumerate(slides):\n",
        "        print(f\"Creating video clip for slide {idx+1}/{len(slides)}...\")\n",
        "        duration = slide_durations_to_use[idx]\n",
        "\n",
        "        # background\n",
        "        bg_array = np.full((HEIGHT, WIDTH, 3), BG_COLOR, dtype=np.uint8)\n",
        "        bg = ImageClip(bg_array).set_duration(duration)\n",
        "\n",
        "        # title text - Wrap in try-except block for safety\n",
        "        try:\n",
        "            txt_clip = TextClip(\n",
        "                slide[\"title\"],\n",
        "                fontsize=70,\n",
        "                font=AVAILABLE_FONT, # Use pre-defined font\n",
        "                color=\"white\",\n",
        "                size=(WIDTH*0.85, None), # Limit width slightly more\n",
        "                method='caption', # Allow wrapping\n",
        "                align='center'\n",
        "            ).set_position((\"center\", 0.1), relative=True).set_duration(duration)\n",
        "            layers = [bg, txt_clip]\n",
        "        except Exception as e:\n",
        "             print(f\"ERROR creating TextClip for slide {idx+1}: {e}\")\n",
        "             print(\"This might happen if ImageMagick is still not configured correctly.\")\n",
        "             print(\"Using background only for this slide.\")\n",
        "             layers = [bg] # Fallback to background only\n",
        "\n",
        "\n",
        "        # infographic overlay\n",
        "        if slide.get(\"infographic\") and idx in chart_paths:\n",
        "            try:\n",
        "                chart_clip = (\n",
        "                    ImageClip(chart_paths[idx], transparent=True)\n",
        "                    .resize(height=HEIGHT * 0.5) # Relative sizing\n",
        "                    .set_position((\"center\", \"center\"))\n",
        "                    .set_duration(duration)\n",
        "                    # Optional fade in/out for chart (adds render time)\n",
        "                    # .crossfadein(0.5).set_start(0.5).crossfadeout(0.5)\n",
        "                )\n",
        "                layers.append(chart_clip)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not load or add chart for slide {idx+1}. Error: {e}\")\n",
        "\n",
        "        final_clip = CompositeVideoClip(layers, size=(WIDTH, HEIGHT))\n",
        "        clips.append(final_clip)\n",
        "\n",
        "    print(\"Video clip creation complete.\")\n",
        "\n",
        "    # 4. Concatenate video + audio\n",
        "    print(\"\\n--- Concatenating Video and Audio ---\")\n",
        "\n",
        "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "    # Load valid audio clips only if TTS was attempted\n",
        "    valid_audios = []\n",
        "    total_audio_duration = 0\n",
        "    if openai_key_loaded:\n",
        "        print(\"Loading generated audio files...\")\n",
        "        for idx, p in enumerate(audio_files):\n",
        "            if os.path.exists(p) and os.path.getsize(p) > 0:\n",
        "                 try:\n",
        "                    audio_clip = AudioFileClip(p)\n",
        "                    valid_audios.append(audio_clip)\n",
        "                    total_audio_duration += audio_clip.duration\n",
        "                 except Exception as e:\n",
        "                     print(f\"Warning: Could not load audio file {p}. Skipping. Error: {e}\")\n",
        "            else:\n",
        "                 print(f\"Warning: Audio file {p} is missing or empty. Skipping.\")\n",
        "\n",
        "    if valid_audios:\n",
        "        print(f\"Concatenating {len(valid_audios)} audio clips...\")\n",
        "        full_audio = concatenate_audioclips(valid_audios)\n",
        "        # Trim or pad video to match total audio duration\n",
        "        print(f\"Total audio duration: {full_audio.duration:.2f}s\")\n",
        "        print(f\"Total video duration before audio sync: {final_video.duration:.2f}s\")\n",
        "        # Set final video duration to match concatenated audio\n",
        "        final_video = final_video.set_duration(full_audio.duration)\n",
        "        final_video = final_video.set_audio(full_audio)\n",
        "        print(f\"Video duration set to match audio: {final_video.duration:.2f}s\")\n",
        "    else:\n",
        "        print(\"No valid audio found or TTS was skipped. Video will be silent.\")\n",
        "        # Set video duration based on planned slide durations\n",
        "        final_video_duration = sum(slide_durations_to_use)\n",
        "        final_video = final_video.set_duration(final_video_duration)\n",
        "        print(f\"Video duration set to sum of slide durations: {final_video.duration:.2f}s\")\n",
        "\n",
        "\n",
        "    # 5. Export\n",
        "    print(f\"\\n--- Exporting Video ---\")\n",
        "    print(f\"Writing video to: {VIDEO_PATH}\")\n",
        "    final_video.write_videofile(\n",
        "        VIDEO_PATH,\n",
        "        fps=FPS,\n",
        "        codec=\"libx264\", # Good default codec\n",
        "        audio_codec=\"aac\", # Good default audio codec\n",
        "        temp_audiofile=os.path.join(OUTPUT_DIR, \"temp-audio.m4a\"),\n",
        "        remove_temp=True,\n",
        "        preset='medium', # 'medium' is a balance of speed and quality\n",
        "        logger='bar' # Show progress bar\n",
        "    )\n",
        "\n",
        "    print(f\"\\nâœ… Presentation generated: {VIDEO_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ An error occurred during video processing or export: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc() # Print detailed traceback\n",
        "    video_creation_successful = False\n",
        "\n",
        "finally:\n",
        "    # Ensure all moviepy clips are closed to release resources\n",
        "    print(\"\\nClosing resources...\")\n",
        "    for clip in clips:\n",
        "        if isinstance(clip, (CompositeVideoClip, ImageClip, TextClip)):\n",
        "            try: clip.close()\n",
        "            except Exception: pass\n",
        "    if 'valid_audios' in locals():\n",
        "        for audio_clip in valid_audios:\n",
        "            try: audio_clip.close()\n",
        "            except Exception: pass\n",
        "    if 'full_audio' in locals() and full_audio:\n",
        "         try: full_audio.close()\n",
        "         except Exception: pass\n",
        "    if 'final_video' in locals() and final_video:\n",
        "         try: final_video.close()\n",
        "         except Exception: pass\n",
        "    print(\"Resources closed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igUZ-me-hcd2",
        "outputId": "42cdfe26-6473-4efd-a43b-803fb620c187"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building Video Clips ---\n",
            "Video clip durations (seconds): [30, 30, 30, 30, 30, 30, 30]\n",
            "Creating video clip for slide 1/7...\n",
            "ERROR creating TextClip for slide 1: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpflfxcu2g.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpn68mjx9v.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 2/7...\n",
            "ERROR creating TextClip for slide 2: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmp9miubg63.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpfjhkdu5w.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 3/7...\n",
            "ERROR creating TextClip for slide 3: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpwqn1zl4i.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpj5ps1qy2.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 4/7...\n",
            "ERROR creating TextClip for slide 4: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmptu3y7fyn.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpkukb53s6.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 5/7...\n",
            "ERROR creating TextClip for slide 5: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpsyhqq2od.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpdcvfs664.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 6/7...\n",
            "ERROR creating TextClip for slide 6: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmpu65do0_8.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpjn4ybp6a.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Creating video clip for slide 7/7...\n",
            "ERROR creating TextClip for slide 7: MoviePy Error: creation of None failed because of the following error:\n",
            "\n",
            "convert-im6.q16: attempt to perform an operation not allowed by the security policy `@/tmp/tmplrfzees_.txt' @ error/property.c/InterpretImageProperties/3706.\n",
            "convert-im6.q16: no images defined `PNG32:/tmp/tmpqp90he4t.png' @ error/convert.c/ConvertImageCommand/3229.\n",
            ".\n",
            "\n",
            ".This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect\n",
            "This might happen if ImageMagick is still not configured correctly.\n",
            "Using background only for this slide.\n",
            "Video clip creation complete.\n",
            "\n",
            "--- Concatenating Video and Audio ---\n",
            "No valid audio found or TTS was skipped. Video will be silent.\n",
            "Video duration set to sum of slide durations: 210.00s\n",
            "\n",
            "--- Exporting Video ---\n",
            "Writing video to: /content/output/agentic_ai_presentation.mp4\n",
            "Moviepy - Building video /content/output/agentic_ai_presentation.mp4.\n",
            "Moviepy - Writing video /content/output/agentic_ai_presentation.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/output/agentic_ai_presentation.mp4\n",
            "\n",
            "âœ… Presentation generated: /content/output/agentic_ai_presentation.mp4\n",
            "\n",
            "Closing resources...\n",
            "Resources closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the generated video in Colab\n",
        "\n",
        "# Check if video processing seemed successful and file exists\n",
        "if 'video_creation_successful' in locals() and video_creation_successful and os.path.exists(VIDEO_PATH):\n",
        "    print(f\"\\nDisplaying generated video ({VIDEO_PATH}):\")\n",
        "    # Embedding the video using HTML5 video tag for better compatibility\n",
        "    video_html = f\"\"\"\n",
        "    <video width=\"{WIDTH // 2}\" controls preload=\"metadata\">\n",
        "      <source src=\"{VIDEO_PATH}\" type=\"video/mp4\">\n",
        "      Your browser does not support the video tag. You can download the video\n",
        "      from the file browser on the left (folder icon ðŸ“ -> output folder).\n",
        "    </video>\n",
        "    \"\"\"\n",
        "    ipd.display(ipd.HTML(video_html))\n",
        "    print(f\"\\nVideo saved to {VIDEO_PATH}. You can download it from the Colab file browser (folder icon ðŸ“ -> output folder).\")\n",
        "elif os.path.exists(VIDEO_PATH):\n",
        "     print(f\"\\nVideo file {VIDEO_PATH} exists, but there might have been errors during creation.\")\n",
        "     print(\"You can try downloading it from the file browser (folder icon ðŸ“ -> output folder).\")\n",
        "else:\n",
        "    print(\"\\nâŒ Video file not found. Export likely failed due to errors in the previous steps.\")"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/output/agentic_ai_presentation.mp4": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "sPSRDlyqjiJ0",
        "outputId": "c1f61cde-54d4-4834-8dd9-b25a1e6815e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Displaying generated video (/content/output/agentic_ai_presentation.mp4):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <video width=\"640\" controls preload=\"metadata\">\n",
              "      <source src=\"/content/output/agentic_ai_presentation.mp4\" type=\"video/mp4\">\n",
              "      Your browser does not support the video tag. You can download the video\n",
              "      from the file browser on the left (folder icon ðŸ“ -> output folder).\n",
              "    </video>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Video saved to /content/output/agentic_ai_presentation.mp4. You can download it from the Colab file browser (folder icon ðŸ“ -> output folder).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn6ofbjCXxxo",
        "outputId": "510515e1-0e8d-4a79-ab98-89e94f5e2584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secretName')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "HaVe0NNKYHxi",
        "outputId": "db1103f4-a892-45fb-c8cb-eaf406a6f46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret secretName does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-245876ae012f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'secretName'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret secretName does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPEN_AI_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "nUklicTSYJ6G",
        "outputId": "73fbd749-4d15-4ff9-a732-866f341bcf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret OPEN_AI_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-606f83f2618e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPEN_AI_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret OPEN_AI_KEY does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW8AVq81Yl_A",
        "outputId": "180aae94-8486-4174-e30e-6e9223651ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get(import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e)\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "9dXmt6pAYrxB",
        "outputId": "c0a9ece5-ab93-4aff-d67b-8ebd03d42748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-6-b45fc95e63a4>, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b45fc95e63a4>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    openai.api_key = userdata.get(import os\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVFfaD9VY3Bx",
        "outputId": "998e7220-6354-410f-94b3-15f46a519e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "I9XqDKNwY723",
        "outputId": "1f16c2d9-c0f5-417e-a5a4-fba3bc2d123b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 14) (<ipython-input-8-6c69c0ac675c>, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-6c69c0ac675c>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    openai.api_key = userdata.get('import os\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab\n",
        "\n",
        "# Load OpenAI API key from Colab secrets\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab secrets.\")\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\")\n",
        "    # Optionally, raise the error to stop execution if the key is critical\n",
        "    # raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-WW8QiOZDiM",
        "outputId": "01c86091-f88b-4487-f549-29b7f6f3625e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading OpenAI API key: Secret OPENAI_API_KEY does not exist.\n",
            "Please ensure you have added 'OPENAI_API_KEY' to Colab Secrets (Key icon ðŸ”‘ in the left sidebar).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secretName')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "uNwbyDnzZPZA",
        "outputId": "94189822-5e65-43b4-e06f-92b9958f2e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret secretName does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-245876ae012f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'secretName'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret secretName does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import (\n",
        "    ImageClip, TextClip, CompositeVideoClip,\n",
        "    concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata # To access secrets\n",
        "import IPython.display as ipd   # To display video in Colab"
      ],
      "metadata": {
        "id": "XF4Uiv2YZiSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” CONFIGURATION â€”â€”â€”â€”â€”\n",
        "# Use Colab's file system\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "VIDEO_PATH = os.path.join(OUTPUT_DIR, \"agentic_ai_presentation.mp4\")\n",
        "FPS = 24\n",
        "SLIDE_DURATION = 30  # seconds per slide (Adjust if needed based on TTS length)\n",
        "WIDTH, HEIGHT = 1280, 720\n",
        "BG_COLOR = (31, 41, 55)  # dark gray as RGB tuple\n",
        "ACCENT_COLOR = \"#FF6A00\"  # orange accent (Used potentially in charts)\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4tFcfKRZm_k",
        "outputId": "46a3f316-ea27-46e0-cf06-ae8a466ef130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output will be saved to: /content/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” SLIDE CONTENT â€”â€”â€”â€”â€”\n",
        "# (Keep your original slides list here)\n",
        "slides = [\n",
        "    {\n",
        "        \"title\": \"Welcome to Agentic AI\",\n",
        "        \"script\": (\n",
        "            \"Welcome to our exploration of Agentic AI. In the next three and a half minutes, \"\n",
        "            \"we'll dive into a transformative technology shaping the future of intelligent systems. \"\n",
        "            \"Agentic AI enables machines not only to analyze data but also to make autonomous decisions, \"\n",
        "            \"adapt to new contexts, and pursue high-level objectives with minimal human intervention. \"\n",
        "            \"We'll cover its definition, key components, benefits, challenges, real-world use cases, \"\n",
        "            \"and future outlook. Let's get started!\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"What is Agentic AI?\",\n",
        "        \"script\": (\n",
        "            \"At its essence, Agentic AI refers to AI systems endowed with agencyâ€”the capacity to act autonomously \"\n",
        "            \"to achieve goals. It goes beyond traditional AI, which typically executes predefined tasks based on \"\n",
        "            \"pattern recognition or rules. Agentic AI employs perception modules to interpret sensory data, reasoning \"\n",
        "            \"engines to plan actions, and actuation to execute decisions in the world. This triad is the backbone of autonomy.\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Core Components\",\n",
        "        \"script\": (\n",
        "            \"Agentic AIâ€™s core components are perception, reasoning, and actuation. Perception transforms raw inputs \"\n",
        "            \"into meaningful data. Reasoning plans and optimizes actionsâ€”often via reinforcement learning or planning \"\n",
        "            \"algorithms. Actuation interfaces with robots or software APIs to effect change. Together, they form a \"\n",
        "            \"closed loop enabling continuous, autonomous operation.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Perception\", 30), (\"Reasoning\", 30), (\"Actuation\", 40)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Benefits\",\n",
        "        \"script\": (\n",
        "            \"Agentic AI brings efficiency by automating decisions, scalability by adapting without reprogramming, \"\n",
        "            \"and personalization by tailoring interactions in real time. Whether in customer service, logistics, or \"\n",
        "            \"data analytics, these systems reduce costs, accelerate workflows, and unlock new innovation.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Efficiency\", 40), (\"Scalability\", 35), (\"Personalization\", 25)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Challenges\",\n",
        "        \"script\": (\n",
        "            \"Challenges include ethicsâ€”autonomous decisions need accountability and transparencyâ€”complexity, which \"\n",
        "            \"drives up development costs, and trust: ensuring safety in unpredictable environments. Regulatory \"\n",
        "            \"compliance in healthcare, finance, and beyond also demands clear governance frameworks.\"\n",
        "        ),\n",
        "        \"infographic\": True,\n",
        "        \"chart_data\": [(\"Ethics\", 30), (\"Complexity\", 45), (\"Trust\", 25)]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Real-World Use Cases\",\n",
        "        \"script\": (\n",
        "            \"Agentic AI powers warehouse robots that navigate dynamic spaces, trading bots making real-time market \"\n",
        "            \"decisions, and conversational agents handling complex queries. In smart cities, it optimizes traffic \"\n",
        "            \"and energy. These examples show how autonomous decision-making is already transforming industries.\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Future Outlook & Conclusion\",\n",
        "        \"script\": (\n",
        "            \"Looking ahead, hybrid architectures combining symbolic reasoning and deep learning will boost robustness. \"\n",
        "            \"Embedding explainability and fairness will build trust. As Agentic AI matures, weâ€™ll see more self-managing \"\n",
        "            \"enterprises and humanâ€“AI collaborations. Thank you for joining this journey into Agentic AIâ€”exciting times lie ahead!\"\n",
        "        ),\n",
        "        \"infographic\": False\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "88VCf-_FZq_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” HELPERS â€”â€”â€”â€”â€”\n",
        "def generate_tts(text: str, out_path: str):\n",
        "    \"\"\"\n",
        "    Uses OpenAIâ€™s TTS (Onyx voice) to synthesize a .mp3 file.\n",
        "    Requires the openai library and API key to be configured.\n",
        "    \"\"\"\n",
        "    if not openai.api_key:\n",
        "      print(\"Skipping TTS generation as OpenAI API key is not configured.\")\n",
        "      # Create a dummy empty file to avoid errors later\n",
        "      with open(out_path, \"wb\") as f:\n",
        "          pass # Write nothing, creates an empty file\n",
        "      return False # Indicate failure or skipping\n",
        "\n",
        "    try:\n",
        "        # Note: OpenAI API might return audio data directly, not response object\n",
        "        # Check documentation if API changes. Current SDK uses .audio property\n",
        "        response = openai.audio.speech.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"onyx\",\n",
        "            input=text\n",
        "        )\n",
        "        # The response object has a 'write_to_file' method or you can stream bytes\n",
        "        response.stream_to_file(out_path)\n",
        "        # Old way (might still work depending on version):\n",
        "        # with open(out_path, \"wb\") as f:\n",
        "        #     f.write(response.audio) # Access audio bytes if needed\n",
        "        return True # Indicate success\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating TTS for path {out_path}: {e}\")\n",
        "        # Create a dummy empty file to avoid errors later\n",
        "        with open(out_path, \"wb\") as f:\n",
        "            pass # Write nothing\n",
        "        return False # Indicate failure"
      ],
      "metadata": {
        "id": "DLHJKK31ZxJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â€”â€”â€”â€”â€” MAIN PROCESSING â€”â€”â€”â€”â€”\n",
        "\n",
        "# 1. Generate narration audio\n",
        "print(\"--- Generating Narration Audio ---\")\n",
        "audio_files = []\n",
        "actual_audio_durations = []\n",
        "if openai.api_key: # Only proceed if key is available\n",
        "    for idx, slide in enumerate(slides):\n",
        "        audio_path = os.path.join(OUTPUT_DIR, f\"slide_{idx}.mp3\")\n",
        "        print(f\"Rendering TTS for slide {idx+1}/{len(slides)}...\")\n",
        "        success = generate_tts(slide[\"script\"], audio_path)\n",
        "        audio_files.append(audio_path)\n",
        "        if success and os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:\n",
        "             # Get actual duration for potentially adjusting slide timing later\n",
        "             try:\n",
        "                 temp_audio_clip = AudioFileClip(audio_path)\n",
        "                 actual_audio_durations.append(temp_audio_clip.duration)\n",
        "                 temp_audio_clip.close() # Close the clip to release file handle\n",
        "             except Exception as e:\n",
        "                 print(f\"Warning: Could not get duration for {audio_path}. Using default. Error: {e}\")\n",
        "                 actual_audio_durations.append(SLIDE_DURATION) # Fallback\n",
        "        else:\n",
        "             print(f\"Warning: TTS failed or produced empty file for slide {idx+1}. Using default duration.\")\n",
        "             actual_audio_durations.append(SLIDE_DURATION) # Fallback if TTS failed\n",
        "else:\n",
        "    print(\"Skipping TTS generation as API key is missing.\")\n",
        "    # Create placeholder entries if TTS is skipped\n",
        "    audio_files = [os.path.join(OUTPUT_DIR, f\"slide_{idx}.mp3\") for idx in range(len(slides))]\n",
        "    actual_audio_durations = [SLIDE_DURATION] * len(slides) # Use default duration\n",
        "    # Ensure dummy files exist if generate_tts didn't create them\n",
        "    for audio_path in audio_files:\n",
        "        if not os.path.exists(audio_path):\n",
        "            with open(audio_path, 'wb') as f: pass\n",
        "\n",
        "print(f\"Actual audio durations (seconds): {actual_audio_durations}\")\n",
        "# Optional: You could adjust SLIDE_DURATION dynamically based on these actuals\n",
        "# For simplicity, we'll stick to the fixed SLIDE_DURATION for video clips,\n",
        "# but the concatenated audio will have its real length. Moviepy handles this.\n",
        "\n",
        "# 2. Generate infographics\n",
        "print(\"\\n--- Generating Infographics ---\")\n",
        "chart_paths = {}\n",
        "for idx, slide in enumerate(slides):\n",
        "    if slide.get(\"infographic\"):\n",
        "        chart_path = os.path.join(OUTPUT_DIR, f\"chart_{idx}.png\")\n",
        "        print(f\"Generating chart for slide {idx+1}...\")\n",
        "        try:\n",
        "            labels, vals = zip(*slide[\"chart_data\"])\n",
        "            fig, ax = plt.subplots(figsize=(6, 4)) # Slightly bigger figure\n",
        "            bars = ax.bar(labels, vals, color=ACCENT_COLOR)\n",
        "            ax.set_title(slide[\"title\"], fontsize=14, color='white')\n",
        "            ax.tick_params(axis='x', colors='white', labelsize=10)\n",
        "            ax.set_yticks([]) # Hide Y axis ticks/labels\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.spines['left'].set_visible(False)\n",
        "            ax.spines['bottom'].set_color('white')\n",
        "            ax.set_facecolor(f'rgb{BG_COLOR}') # Match background\n",
        "            fig.patch.set_facecolor(f'rgb{BG_COLOR}') # Match figure background too\n",
        "\n",
        "            # Add value labels on top of bars\n",
        "            for bar in bars:\n",
        "              height = bar.get_height()\n",
        "              ax.annotate(f'{height}',\n",
        "                          xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                          xytext=(0, 3),  # 3 points vertical offset\n",
        "                          textcoords=\"offset points\",\n",
        "                          ha='center', va='bottom', color='white', fontsize=10)\n",
        "\n",
        "            plt.savefig(chart_path, bbox_inches=\"tight\", facecolor=fig.get_facecolor(), transparent=True) # Use transparent BG on save\n",
        "            plt.close(fig) # Close the figure to free memory\n",
        "            chart_paths[idx] = chart_path\n",
        "            print(f\"Chart saved to {chart_path}\")\n",
        "            # Display the chart in Colab output\n",
        "            ipd.display(ipd.Image(chart_path))\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating chart for slide {idx+1}: {e}\")\n",
        "\n",
        "print(\"\\nInfographics generation complete.\")"
      ],
      "metadata": {
        "id": "gll_PQPbZ1_c",
        "outputId": "fe9be04f-4500-46c3-f829-b341a7822124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Narration Audio ---\n",
            "Skipping TTS generation as API key is missing.\n",
            "Actual audio durations (seconds): [30, 30, 30, 30, 30, 30, 30]\n",
            "\n",
            "--- Generating Infographics ---\n",
            "Generating chart for slide 3...\n",
            "Error generating chart for slide 3: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "Generating chart for slide 4...\n",
            "Error generating chart for slide 4: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "Generating chart for slide 5...\n",
            "Error generating chart for slide 5: Invalid RGBA argument: 'rgb(31, 41, 55)'\n",
            "\n",
            "Infographics generation complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAF3CAYAAACbnlMqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABjhJREFUeJzt2MFNxFAQBUGMfOBCpI7H8Q4HUsBM76oqgXkHS63vY2bmAwBY97k9AAD4JcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAECHKABAhygAQIcoAEHGuXr+O1fP8g3u2FwC8DC9lAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiDi3B8AjrmN7AU+7Z3sB/DkvZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIgQZQCIEGUAiBBlAIg4twcAvJTr2F7A0+5ZO+2lDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAARogwAEaIMABGiDAAR5+r1r+/V87wx3xZP8W3xoGNmZnsEAOD3NQBkiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAESIMgBEiDIARIgyAET8AD16ESzOT2RVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secretName')"
      ],
      "metadata": {
        "id": "L89tglvVZUaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Presentation Generator in Colab\n",
        "\n",
        "This notebook takes presentation slide content (title, script, optional chart data) and generates a video presentation with:\n",
        "* Text overlays for titles.\n",
        "* Generated voice narration using OpenAI's Text-to-Speech (TTS).\n",
        "* Optional simple bar charts as infographics."
      ],
      "metadata": {
        "id": "lLBRjqaAXnBj"
      }
    }
  ]
}